{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 7: DBSCAN on a Real-World Dataset for Anomaly Detection\n",
    "# Description: Perform DBSCAN on a credit card transaction dataset to detect anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic credit card transaction data...\n",
      "Synthetic dataset created with 1020 transactions (1000 normal, 20 fraud).\n",
      "         V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0  0.248357 -0.069132  0.323844  0.761515 -0.117077 -0.117068  0.789606   \n",
      "1 -0.300319 -0.145847 -0.300853  0.926139 -0.006749 -0.528855  0.411272   \n",
      "2 -0.419609 -0.154606  0.165632  0.487773 -0.239587 -0.092829 -0.553167   \n",
      "3 -0.404247 -0.250879  0.457701  0.164376 -0.264880  0.256634  0.048539   \n",
      "4  0.030115  1.231621 -0.096180  0.150774 -0.017356 -0.584339  0.571411   \n",
      "\n",
      "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
      "0  0.383717 -0.234737  0.271280  ...  0.732824 -0.112888  0.033764 -0.712374   \n",
      "1 -0.610422  0.104432 -0.979835  ...  0.171809 -0.881520  0.162042 -0.192541   \n",
      "2 -0.598103  0.406263  0.678120  ...  0.043524 -0.149504  0.045880 -0.993784   \n",
      "3  0.484322 -0.351027 -0.163831  ... -0.080643  0.202025  0.943093  0.087289   \n",
      "4  0.375967  0.395516 -0.454694  ... -0.531152  0.236796 -0.459712  0.774967   \n",
      "\n",
      "        V25       V26       V27       V28     Amount  Class  \n",
      "0 -0.272191  0.055461 -0.575497  0.187849  67.347107    0.0  \n",
      "1 -0.338461  0.305838  0.515500  0.465640  79.061036    0.0  \n",
      "2 -0.109836  0.178556  0.738947 -0.259135  30.828031    0.0  \n",
      "3  0.128775 -0.037223 -0.959386 -0.013257  81.918935    0.0  \n",
      "4 -0.391627 -0.161031  0.406759 -0.615432  68.743286    0.0  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "            V1        V2        V3        V4        V5        V6        V7  \\\n",
      "1015  2.104027  8.166901  3.000166  3.673757  4.062759  3.142171  2.920368   \n",
      "1016  2.265698  7.469034  2.567785  4.174960  4.766778  1.167784  3.917548   \n",
      "1017  9.843890  6.729949  5.311305  5.291923  3.589502  3.488684  7.706351   \n",
      "1018  1.132565  7.396723  3.277933  7.744432  3.511779  3.909938  4.134958   \n",
      "1019  7.078197  5.092059  5.837355  4.736816  5.673874  8.000230  1.201311   \n",
      "\n",
      "            V8        V9       V10  ...        V21       V22       V23  \\\n",
      "1015  2.386629  9.201970  7.040302  ...   7.744836  5.768502  1.392055   \n",
      "1016  7.743510  7.188362  8.339044  ...   5.605686  5.927970  6.054224   \n",
      "1017  2.108989  9.844318  4.544830  ...   0.824344  6.745031  5.386700   \n",
      "1018  3.027934  9.197814  7.695581  ...  12.279417  8.653738  9.731913   \n",
      "1019  0.521233  6.277594  9.321723  ...   9.778935  5.021855  3.794617   \n",
      "\n",
      "            V24       V25       V26        V27       V28       Amount  Class  \n",
      "1015  11.457977  6.948616  7.332230   8.855086  0.079353   608.555013    1.0  \n",
      "1016   8.586992  4.974281  8.025108   6.549756  8.388901   860.840019    1.0  \n",
      "1017   2.246830  2.633355 -1.100354  10.152333  8.046261  1297.992772    1.0  \n",
      "1018   6.019176  5.997473  1.899544   7.855466  4.780455   913.844202    1.0  \n",
      "1019   6.760548  7.817858  9.787926   4.370093  8.258170  1086.171185    1.0  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "\n",
      "Data scaled using StandardScaler.\n",
      "Shape of scaled data: (1020, 29)\n",
      "\n",
      "Applying DBSCAN with eps=2.0 and min_samples=5...\n",
      "\n",
      "DBSCAN clustering complete.\n",
      "Number of clusters found (excluding noise): 0\n",
      "Number of anomalies detected (noise points): 1020\n",
      "\n",
      "--- Anomaly Detection Results ---\n",
      "True number of fraudulent transactions: 20\n",
      "Number of transactions DBSCAN labeled as anomalies: 1020\n",
      "Fraudulent transactions correctly identified as anomalies: 20\n",
      "Normal transactions incorrectly labeled as anomalies (False Positives): 1000\n",
      "\n",
      "Sample of Detected Anomalies:\n",
      "         V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0  0.248357 -0.069132  0.323844  0.761515 -0.117077 -0.117068  0.789606   \n",
      "1 -0.300319 -0.145847 -0.300853  0.926139 -0.006749 -0.528855  0.411272   \n",
      "2 -0.419609 -0.154606  0.165632  0.487773 -0.239587 -0.092829 -0.553167   \n",
      "3 -0.404247 -0.250879  0.457701  0.164376 -0.264880  0.256634  0.048539   \n",
      "4  0.030115  1.231621 -0.096180  0.150774 -0.017356 -0.584339  0.571411   \n",
      "\n",
      "         V8        V9       V10  ...       V23       V24       V25       V26  \\\n",
      "0  0.383717 -0.234737  0.271280  ...  0.033764 -0.712374 -0.272191  0.055461   \n",
      "1 -0.610422  0.104432 -0.979835  ...  0.162042 -0.192541 -0.338461  0.305838   \n",
      "2 -0.598103  0.406263  0.678120  ...  0.045880 -0.993784 -0.109836  0.178556   \n",
      "3  0.484322 -0.351027 -0.163831  ...  0.943093  0.087289  0.128775 -0.037223   \n",
      "4  0.375967  0.395516 -0.454694  ... -0.459712  0.774967 -0.391627 -0.161031   \n",
      "\n",
      "        V27       V28     Amount  Class  cluster  is_anomaly  \n",
      "0 -0.575497  0.187849  67.347107    0.0       -1        True  \n",
      "1  0.515500  0.465640  79.061036    0.0       -1        True  \n",
      "2  0.738947 -0.259135  30.828031    0.0       -1        True  \n",
      "3 -0.959386 -0.013257  81.918935    0.0       -1        True  \n",
      "4  0.406759 -0.615432  68.743286    0.0       -1        True  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "\n",
      "Sample of Missed True Anomalies (False Negatives - if any):\n",
      "Empty DataFrame\n",
      "Columns: [V1, V2, V3, V4, V5, V6, V7, V8, V9, V10, V11, V12, V13, V14, V15, V16, V17, V18, V19, V20, V21, V22, V23, V24, V25, V26, V27, V28, Amount, Class, cluster, is_anomaly]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Description: Perform DBSCAN on a credit card transaction dataset to detect anomalies.\n",
    "\n",
    "# Step 1: Load a sample credit card transaction dataset.\n",
    "# As I cannot directly download or access local files, I'll create a synthetic\n",
    "# dataset that mimics some characteristics of a real credit card transaction dataset.\n",
    "# In a real scenario, you would replace this with pd.read_csv('creditcard.csv')\n",
    "# For a real dataset, you might need to handle 'Time' and 'Amount' features carefully.\n",
    "# 'V1' through 'V28' are usually anonymized principal components.\n",
    "\n",
    "print(\"Generating synthetic credit card transaction data...\")\n",
    "np.random.seed(42) # for reproducibility\n",
    "\n",
    "# Normal transactions\n",
    "num_normal = 1000\n",
    "data_normal = np.random.randn(num_normal, 28) * 0.5\n",
    "amount_normal = np.random.rand(num_normal) * 100 + 10 # Amounts between 10 and 110\n",
    "\n",
    "# Anomalous transactions (simulating fraud)\n",
    "num_fraud = 20\n",
    "data_fraud = np.random.randn(num_fraud, 28) * 3 + 5 # Higher variance and shifted mean\n",
    "amount_fraud = np.random.rand(num_fraud) * 1000 + 500 # Larger amounts\n",
    "\n",
    "# Combine normal and fraud data\n",
    "X = np.vstack((data_normal, data_fraud))\n",
    "amounts = np.hstack((amount_normal, amount_fraud))\n",
    "y_true = np.hstack((np.zeros(num_normal), np.ones(num_fraud))) # 0 for normal, 1 for fraud\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(X, columns=[f'V{i}' for i in range(1, 29)])\n",
    "df['Amount'] = amounts\n",
    "df['Class'] = y_true # This 'Class' column would not be available during actual anomaly detection\n",
    "\n",
    "print(f\"Synthetic dataset created with {len(df)} transactions ({num_normal} normal, {num_fraud} fraud).\")\n",
    "print(df.head())\n",
    "print(df.tail())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Step 2: Preprocess the data.\n",
    "# For DBSCAN, scaling is crucial as it's a distance-based algorithm.\n",
    "# We'll scale all numerical features. 'Class' is our target and won't be used in clustering.\n",
    "features = df.drop('Class', axis=1).columns\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df[features])\n",
    "\n",
    "print(\"Data scaled using StandardScaler.\")\n",
    "print(f\"Shape of scaled data: {X_scaled.shape}\\n\")\n",
    "\n",
    "# Step 3: Apply DBSCAN.\n",
    "# Key parameters for DBSCAN:\n",
    "# - eps: The maximum distance between two samples for one to be considered as in the neighborhood of the other.\n",
    "# - min_samples: The number of samples (or total weight) in a neighborhood for a point to be considered as a core point.\n",
    "#                This includes the point itself.\n",
    "# Adjusting these parameters is critical for good performance.\n",
    "# For anomaly detection, points labeled as -1 (noise) are considered anomalies.\n",
    "\n",
    "# Let's try some initial parameters. These often require tuning.\n",
    "# For a dataset with many dimensions (like V1-V28), finding a good eps can be challenging.\n",
    "# A rule of thumb for min_samples can be 2 * number_of_features.\n",
    "eps_val = 2.0 # This value is highly dependent on the scaled data and its density\n",
    "min_samples_val = 5 # Minimum samples to form a dense region\n",
    "\n",
    "print(f\"Applying DBSCAN with eps={eps_val} and min_samples={min_samples_val}...\")\n",
    "dbscan = DBSCAN(eps=eps_val, min_samples=min_samples_val)\n",
    "clusters = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# Step 4: Identify anomalies.\n",
    "# In DBSCAN, points labeled as -1 are considered noise or outliers.\n",
    "df['cluster'] = clusters\n",
    "df['is_anomaly'] = (df['cluster'] == -1)\n",
    "\n",
    "print(\"\\nDBSCAN clustering complete.\")\n",
    "print(f\"Number of clusters found (excluding noise): {len(np.unique(clusters[clusters != -1]))}\")\n",
    "print(f\"Number of anomalies detected (noise points): {np.sum(df['is_anomaly'])}\")\n",
    "\n",
    "# Step 5: Evaluate (if ground truth is available).\n",
    "# Since we generated the data with a 'Class' label, we can compare DBSCAN's output\n",
    "# with the true fraud labels to see how well it performed.\n",
    "print(\"\\n--- Anomaly Detection Results ---\")\n",
    "\n",
    "true_anomalies = df[df['Class'] == 1]\n",
    "detected_anomalies = df[df['is_anomaly'] == True]\n",
    "\n",
    "print(f\"True number of fraudulent transactions: {len(true_anomalies)}\")\n",
    "print(f\"Number of transactions DBSCAN labeled as anomalies: {len(detected_anomalies)}\")\n",
    "\n",
    "# Check how many true anomalies were detected\n",
    "correctly_detected_fraud = df[(df['Class'] == 1) & (df['is_anomaly'] == True)]\n",
    "print(f\"Fraudulent transactions correctly identified as anomalies: {len(correctly_detected_fraud)}\")\n",
    "\n",
    "# Check how many normal transactions were incorrectly labeled as anomalies (false positives)\n",
    "false_positives = df[(df['Class'] == 0) & (df['is_anomaly'] == True)]\n",
    "print(f\"Normal transactions incorrectly labeled as anomalies (False Positives): {len(false_positives)}\")\n",
    "\n",
    "# Display some detected anomalies\n",
    "print(\"\\nSample of Detected Anomalies:\")\n",
    "print(df[df['is_anomaly'] == True].head())\n",
    "\n",
    "# Display some true anomalies that might have been missed (false negatives)\n",
    "print(\"\\nSample of Missed True Anomalies (False Negatives - if any):\")\n",
    "missed_fraud = df[(df['Class'] == 1) & (df['is_anomaly'] == False)]\n",
    "print(missed_fraud.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
