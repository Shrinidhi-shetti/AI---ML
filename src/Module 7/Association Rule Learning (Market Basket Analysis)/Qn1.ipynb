{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title: Apriori Algorithm\n",
    "\n",
    "# Task 1: Grocery Store Transactions\n",
    "# Dataset: {Milk, Bread}, {Milk, Diaper, Beer, Bread}, {Milk, Diaper, Beer, Coke}, {Bread, Egg, Milk}, {Bread, Egg, Diaper, Milk, Beer}\n",
    "# Task: Identify frequent item sets using the Apriori Algorithm with a minimum support threshold of 50%.\n",
    "\n",
    "# Task 2: Retail Store Data\n",
    "# Dataset: {Shirt, Tie}, {Shirt, Belt, Tie}, {Shirt, Belt}, {Tie, Belt}, {Shirt, Tie, Belt}\n",
    "# Task: Generate association rules after identifying frequent itemsets with a confidence threshold of 60%.\n",
    "\n",
    "# Task 3: Bookstore Purchases\n",
    "# Dataset: {Book A, Book B}, {Book A, Book C}, {Book B, Book C, Book A}, {Book B, Book D}\n",
    "# Task: Use the Apriori algorithm to find rules with a support threshold of 40% and confidence threshold of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets (Task 1 - Grocery Store Transactions):\n",
      "L1: {frozenset({'Milk'}): 5, frozenset({'Bread'}): 4, frozenset({'Diaper'}): 3, frozenset({'Beer'}): 3}\n",
      "L2: {frozenset({'Milk', 'Beer'}): 3, frozenset({'Milk', 'Diaper'}): 3, frozenset({'Milk', 'Bread'}): 4, frozenset({'Diaper', 'Beer'}): 3}\n",
      "L3: {frozenset({'Milk', 'Diaper', 'Beer'}): 3}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def apriori_task1(transactions, min_support):\n",
    "    # Count occurrences of individual items\n",
    "    item_counts = defaultdict(int)\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            item_counts[item] += 1\n",
    "\n",
    "    num_transactions = len(transactions)\n",
    "\n",
    "    # Generate initial frequent 1-itemsets\n",
    "    frequent_items = {frozenset([item]): count for item, count in item_counts.items() if count / num_transactions >= min_support}\n",
    "    frequent_itemsets = {1: frequent_items}\n",
    "\n",
    "    k = 2\n",
    "    while True:\n",
    "        candidate_itemsets = set()\n",
    "        prev_frequent_itemsets = frequent_itemsets[k - 1]\n",
    "\n",
    "        # Generate candidates for k-itemsets from (k-1)-itemsets\n",
    "        # This part of candidate generation in your original code is a bit off\n",
    "        # It should combine itemsets from the previous level.\n",
    "        # A common way is to join itemsets that share k-2 items.\n",
    "        for itemset1 in prev_frequent_itemsets:\n",
    "            for itemset2 in prev_frequent_itemsets:\n",
    "                union = itemset1.union(itemset2)\n",
    "                if len(union) == k:\n",
    "                    # Pruning step: Ensure all (k-1)-subsets are frequent\n",
    "                    is_valid_candidate = True\n",
    "                    for subset in itertools.combinations(union, k - 1):\n",
    "                        if frozenset(subset) not in prev_frequent_itemsets:\n",
    "                            is_valid_candidate = False\n",
    "                            break\n",
    "                    if is_valid_candidate:\n",
    "                        candidate_itemsets.add(union)\n",
    "\n",
    "        current_frequent_itemsets = {}\n",
    "        for candidate in candidate_itemsets:\n",
    "            count = 0\n",
    "            for transaction in transactions:\n",
    "                if candidate.issubset(transaction):\n",
    "                    count += 1\n",
    "            if count / num_transactions >= min_support:\n",
    "                current_frequent_itemsets[candidate] = count\n",
    "\n",
    "        if not current_frequent_itemsets:\n",
    "            break\n",
    "        frequent_itemsets[k] = current_frequent_itemsets\n",
    "        k += 1\n",
    "\n",
    "    return frequent_itemsets\n",
    "\n",
    "import itertools # Added for combinations\n",
    "\n",
    "transactions_task1 = [\n",
    "    frozenset(['Milk', 'Bread']),\n",
    "    frozenset(['Milk', 'Diaper', 'Beer', 'Bread']),\n",
    "    frozenset(['Milk', 'Diaper', 'Beer', 'Coke']),\n",
    "    frozenset(['Bread', 'Egg', 'Milk']),\n",
    "    frozenset(['Bread', 'Egg', 'Diaper', 'Milk', 'Beer'])\n",
    "]\n",
    "min_support_task1 = 0.5\n",
    "\n",
    "frequent_itemsets_task1 = apriori_task1(transactions_task1, min_support_task1)\n",
    "\n",
    "print(\"Frequent Itemsets (Task 1 - Grocery Store Transactions):\")\n",
    "for k, itemsets in frequent_itemsets_task1.items():\n",
    "    print(f\"L{k}: {itemsets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Association Rules (Task 2 - Retail Store Data):\n",
      "  antecedents consequents  antecedent support  consequent support  support  \\\n",
      "0     (Shirt)      (Belt)                 0.8                 0.8      0.6   \n",
      "1      (Belt)     (Shirt)                 0.8                 0.8      0.6   \n",
      "2       (Tie)      (Belt)                 0.8                 0.8      0.6   \n",
      "3      (Belt)       (Tie)                 0.8                 0.8      0.6   \n",
      "4       (Tie)     (Shirt)                 0.8                 0.8      0.6   \n",
      "5     (Shirt)       (Tie)                 0.8                 0.8      0.6   \n",
      "\n",
      "   confidence    lift  representativity  leverage  conviction  zhangs_metric  \\\n",
      "0        0.75  0.9375               1.0     -0.04         0.8          -0.25   \n",
      "1        0.75  0.9375               1.0     -0.04         0.8          -0.25   \n",
      "2        0.75  0.9375               1.0     -0.04         0.8          -0.25   \n",
      "3        0.75  0.9375               1.0     -0.04         0.8          -0.25   \n",
      "4        0.75  0.9375               1.0     -0.04         0.8          -0.25   \n",
      "5        0.75  0.9375               1.0     -0.04         0.8          -0.25   \n",
      "\n",
      "   jaccard  certainty  kulczynski  \n",
      "0      0.6      -0.25        0.75  \n",
      "1      0.6      -0.25        0.75  \n",
      "2      0.6      -0.25        0.75  \n",
      "3      0.6      -0.25        0.75  \n",
      "4      0.6      -0.25        0.75  \n",
      "5      0.6      -0.25        0.75  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "transactions_task2 = [\n",
    "    ['Shirt', 'Tie'],\n",
    "    ['Shirt', 'Belt', 'Tie'],\n",
    "    ['Shirt', 'Belt'],\n",
    "    ['Tie', 'Belt'],\n",
    "    ['Shirt', 'Tie', 'Belt']\n",
    "]\n",
    "\n",
    "te_task2 = TransactionEncoder()\n",
    "te_ary_task2 = te_task2.fit(transactions_task2).transform(transactions_task2)\n",
    "df_task2 = pd.DataFrame(te_ary_task2, columns=te_task2.columns_)\n",
    "\n",
    "# Identify frequent itemsets with a minimum support threshold of 60% (0.6)\n",
    "frequent_itemsets_task2 = apriori(df_task2, min_support=0.6, use_colnames=True)\n",
    "\n",
    "# Generate association rules with a confidence threshold of 60% (0.6)\n",
    "rules_task2 = association_rules(frequent_itemsets_task2, metric=\"confidence\", min_threshold=0.6)\n",
    "\n",
    "print(\"\\nAssociation Rules (Task 2 - Retail Store Data):\")\n",
    "print(rules_task2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "transactions_task3 = [\n",
    "    ['Book A', 'Book B'],\n",
    "    ['Book A', 'Book C'],\n",
    "    ['Book B', 'Book C', 'Book A'],\n",
    "    ['Book B', 'Book D']\n",
    "]\n",
    "\n",
    "te_task3 = TransactionEncoder()\n",
    "te_ary_task3 = te_task3.fit(transactions_task3).transform(transactions_task3)\n",
    "df_task3 = pd.DataFrame(te_ary_task3, columns=te_task3.columns_)\n",
    "\n",
    "# Identify frequent itemsets with a minimum support threshold of 40% (0.4)\n",
    "frequent_itemsets_task3 = apriori(df_task3, min_support=0.4, use_colnames=True)\n",
    "\n",
    "# Generate association rules with a confidence threshold of 70% (0.7)\n",
    "rules_task3 = association_rules(frequent_itemsets_task3, metric=\"confidence\", min_threshold=0.7)\n",
    "\n",
    "print(\"\\nAssociation Rules (Task 3 - Bookstore Purchases):\")\n",
    "print(rules_task3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
