{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3: Implement Apriori algorithm on a simple transaction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent 1-itemsets:\n",
      "  ['Milk']: 3\n",
      "  ['Onion']: 4\n",
      "  ['Kidney Beans']: 5\n",
      "  ['Eggs']: 4\n",
      "  ['Yogurt']: 3\n",
      "Frequent 2-itemsets:\n",
      "  ['Eggs', 'Onion']: 3\n",
      "  ['Kidney Beans', 'Yogurt']: 3\n",
      "  ['Kidney Beans', 'Eggs']: 4\n",
      "  ['Kidney Beans', 'Milk']: 3\n",
      "  ['Kidney Beans', 'Onion']: 3\n",
      "Frequent 3-itemsets:\n",
      "  ['Kidney Beans', 'Eggs', 'Onion']: 3\n",
      "\n",
      "Association Rules:\n",
      "  ['Eggs'] -> ['Onion'] (Support: 3, Confidence: 0.75)\n",
      "  ['Onion'] -> ['Eggs'] (Support: 3, Confidence: 0.75)\n",
      "  ['Yogurt'] -> ['Kidney Beans'] (Support: 3, Confidence: 1.00)\n",
      "  ['Kidney Beans'] -> ['Eggs'] (Support: 4, Confidence: 0.80)\n",
      "  ['Eggs'] -> ['Kidney Beans'] (Support: 4, Confidence: 1.00)\n",
      "  ['Milk'] -> ['Kidney Beans'] (Support: 3, Confidence: 1.00)\n",
      "  ['Onion'] -> ['Kidney Beans'] (Support: 3, Confidence: 0.75)\n",
      "  ['Eggs'] -> ['Kidney Beans', 'Onion'] (Support: 3, Confidence: 0.75)\n",
      "  ['Onion'] -> ['Kidney Beans', 'Eggs'] (Support: 3, Confidence: 0.75)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "def generate_frequent_itemsets(transactions, min_support):\n",
    "    item_counts = defaultdict(int)\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            item_counts[frozenset([item])] += 1\n",
    "    \n",
    "    L1 = {itemset: count for itemset, count in item_counts.items() if count >= min_support}\n",
    "    \n",
    "    frequent_itemsets = {1: L1}\n",
    "    k = 2\n",
    "    while True:\n",
    "        Ck = generate_candidate_itemsets(frequent_itemsets[k-1], k)\n",
    "        Lk = defaultdict(int)\n",
    "        for transaction in transactions:\n",
    "            for candidate in Ck:\n",
    "                if candidate.issubset(transaction):\n",
    "                    Lk[candidate] += 1\n",
    "        \n",
    "        Lk = {itemset: count for itemset, count in Lk.items() if count >= min_support}\n",
    "        if not Lk:\n",
    "            break\n",
    "        frequent_itemsets[k] = Lk\n",
    "        k += 1\n",
    "    return frequent_itemsets\n",
    "\n",
    "def generate_candidate_itemsets(Lk_minus_1, k):\n",
    "    candidates = set()\n",
    "    items = sorted(list(Lk_minus_1.keys()))\n",
    "    for i in range(len(items)):\n",
    "        for j in range(i + 1, len(items)):\n",
    "            itemset1 = list(items[i])\n",
    "            itemset2 = list(items[j])\n",
    "            \n",
    "            itemset1.sort()\n",
    "            itemset2.sort()\n",
    "\n",
    "            if k == 2 or itemset1[:-1] == itemset2[:-1]:\n",
    "                new_candidate = frozenset(sorted(list(itemset1) + list(itemset2)))\n",
    "                candidates.add(new_candidate)\n",
    "    return candidates\n",
    "\n",
    "def generate_association_rules(frequent_itemsets, min_confidence):\n",
    "    rules = []\n",
    "    for k, Lk in frequent_itemsets.items():\n",
    "        if k > 1:\n",
    "            for itemset in Lk:\n",
    "                for antecedent in combinations(itemset, 1):\n",
    "                    antecedent = frozenset(antecedent)\n",
    "                    consequent = itemset - antecedent\n",
    "                    if consequent:\n",
    "                        confidence = Lk[itemset] / frequent_itemsets[len(antecedent)][antecedent]\n",
    "                        if confidence >= min_confidence:\n",
    "                            rules.append((antecedent, consequent, confidence, Lk[itemset]))\n",
    "    return rules\n",
    "transactions = [\n",
    "    ['Milk', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "    ['Dill', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "    ['Milk', 'Apple', 'Kidney Beans', 'Eggs'],\n",
    "    ['Milk', 'Unicorn', 'Corn', 'Kidney Beans', 'Yogurt'],\n",
    "    ['Corn', 'Onion', 'Onion', 'Kidney Beans', 'Ice cream', 'Eggs']\n",
    "]\n",
    "min_support = 3\n",
    "min_confidence = 0.7\n",
    "frequent_itemsets = generate_frequent_itemsets(transactions, min_support)\n",
    "for k, itemsets in frequent_itemsets.items():\n",
    "    print(f\"Frequent {k}-itemsets:\")\n",
    "    for itemset, count in itemsets.items():\n",
    "        print(f\"  {list(itemset)}: {count}\")\n",
    "\n",
    "association_rules = generate_association_rules(frequent_itemsets, min_confidence)\n",
    "print(\"\\nAssociation Rules:\")\n",
    "for antecedent, consequent, confidence, support in association_rules:\n",
    "    print(f\"  {list(antecedent)} -> {list(consequent)} (Support: {support}, Confidence: {confidence:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
