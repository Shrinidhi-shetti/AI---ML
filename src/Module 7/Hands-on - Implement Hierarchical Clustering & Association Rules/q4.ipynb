{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4: Combine hierarchical clustering with Apriori to analyze clustered data and find frequent patterns within each cluster of a given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchical Clustering Results:\n",
      "\n",
      "Cluster 2 (Number of transactions: 5):\n",
      "  ['Milk', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt']\n",
      "  ['Dill', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt']\n",
      "  ['Milk', 'Apple', 'Kidney Beans', 'Eggs']\n",
      "  ['Milk', 'Unicorn', 'Corn', 'Kidney Beans', 'Yogurt']\n",
      "  ['Corn', 'Onion', 'Onion', 'Kidney Beans', 'Ice cream', 'Eggs']\n",
      "\n",
      "Applying Apriori to Cluster 2:\n",
      "  Frequent 1-itemsets:\n",
      "    ['Milk']: 3\n",
      "    ['Onion']: 4\n",
      "    ['Nutmeg']: 2\n",
      "    ['Kidney Beans']: 5\n",
      "    ['Eggs']: 4\n",
      "    ['Yogurt']: 3\n",
      "    ['Corn']: 2\n",
      "  Frequent 2-itemsets:\n",
      "    ['Onion', 'Nutmeg']: 2\n",
      "    ['Onion', 'Kidney Beans']: 3\n",
      "    ['Nutmeg', 'Yogurt']: 2\n",
      "    ['Milk', 'Kidney Beans']: 3\n",
      "    ['Eggs', 'Yogurt']: 2\n",
      "    ['Eggs', 'Nutmeg']: 2\n",
      "    ['Eggs', 'Kidney Beans']: 4\n",
      "    ['Nutmeg', 'Kidney Beans']: 2\n",
      "    ['Onion', 'Eggs']: 3\n",
      "    ['Onion', 'Yogurt']: 2\n",
      "    ['Milk', 'Eggs']: 2\n",
      "    ['Milk', 'Yogurt']: 2\n",
      "    ['Kidney Beans', 'Yogurt']: 3\n",
      "    ['Kidney Beans', 'Corn']: 2\n",
      "  Frequent 3-itemsets:\n",
      "    ['Onion', 'Eggs', 'Nutmeg']: 2\n",
      "    ['Eggs', 'Nutmeg', 'Yogurt']: 2\n",
      "    ['Eggs', 'Kidney Beans', 'Yogurt']: 2\n",
      "    ['Onion', 'Eggs', 'Kidney Beans']: 3\n",
      "    ['Onion', 'Nutmeg', 'Yogurt']: 2\n",
      "    ['Onion', 'Kidney Beans', 'Yogurt']: 2\n",
      "    ['Nutmeg', 'Kidney Beans', 'Yogurt']: 2\n",
      "    ['Milk', 'Kidney Beans', 'Yogurt']: 2\n",
      "    ['Onion', 'Eggs', 'Yogurt']: 2\n",
      "    ['Milk', 'Eggs', 'Kidney Beans']: 2\n",
      "    ['Eggs', 'Kidney Beans', 'Nutmeg']: 2\n",
      "    ['Onion', 'Nutmeg', 'Kidney Beans']: 2\n",
      "  Frequent 4-itemsets:\n",
      "    ['Onion', 'Eggs', 'Kidney Beans', 'Yogurt']: 2\n",
      "    ['Onion', 'Eggs', 'Nutmeg', 'Yogurt']: 2\n",
      "    ['Eggs', 'Kidney Beans', 'Nutmeg', 'Yogurt']: 2\n",
      "    ['Onion', 'Nutmeg', 'Kidney Beans', 'Yogurt']: 2\n",
      "    ['Onion', 'Eggs', 'Kidney Beans', 'Nutmeg']: 2\n",
      "  Frequent 5-itemsets:\n",
      "    ['Yogurt', 'Kidney Beans', 'Nutmeg', 'Onion', 'Eggs']: 2\n",
      "  Association Rules:\n",
      "    ['Nutmeg'] -> ['Onion'] (Support: 2, Confidence: 1.00)\n",
      "    ['Onion'] -> ['Kidney Beans'] (Support: 3, Confidence: 0.75)\n",
      "    ['Kidney Beans'] -> ['Onion'] (Support: 3, Confidence: 0.60)\n",
      "    ['Nutmeg'] -> ['Yogurt'] (Support: 2, Confidence: 1.00)\n",
      "    ['Yogurt'] -> ['Nutmeg'] (Support: 2, Confidence: 0.67)\n",
      "    ['Milk'] -> ['Kidney Beans'] (Support: 3, Confidence: 1.00)\n",
      "    ['Kidney Beans'] -> ['Milk'] (Support: 3, Confidence: 0.60)\n",
      "    ['Yogurt'] -> ['Eggs'] (Support: 2, Confidence: 0.67)\n",
      "    ['Nutmeg'] -> ['Eggs'] (Support: 2, Confidence: 1.00)\n",
      "    ['Eggs'] -> ['Kidney Beans'] (Support: 4, Confidence: 1.00)\n",
      "    ['Kidney Beans'] -> ['Eggs'] (Support: 4, Confidence: 0.80)\n",
      "    ['Nutmeg'] -> ['Kidney Beans'] (Support: 2, Confidence: 1.00)\n",
      "    ['Onion'] -> ['Eggs'] (Support: 3, Confidence: 0.75)\n",
      "    ['Eggs'] -> ['Onion'] (Support: 3, Confidence: 0.75)\n",
      "    ['Yogurt'] -> ['Onion'] (Support: 2, Confidence: 0.67)\n",
      "    ['Milk'] -> ['Eggs'] (Support: 2, Confidence: 0.67)\n",
      "    ['Milk'] -> ['Yogurt'] (Support: 2, Confidence: 0.67)\n",
      "    ['Yogurt'] -> ['Milk'] (Support: 2, Confidence: 0.67)\n",
      "    ['Kidney Beans'] -> ['Yogurt'] (Support: 3, Confidence: 0.60)\n",
      "    ['Yogurt'] -> ['Kidney Beans'] (Support: 3, Confidence: 1.00)\n",
      "    ['Corn'] -> ['Kidney Beans'] (Support: 2, Confidence: 1.00)\n",
      "    ['Nutmeg'] -> ['Onion', 'Eggs'] (Support: 2, Confidence: 1.00)\n",
      "    ['Nutmeg'] -> ['Eggs', 'Yogurt'] (Support: 2, Confidence: 1.00)\n",
      "    ['Yogurt'] -> ['Eggs', 'Nutmeg'] (Support: 2, Confidence: 0.67)\n",
      "    ['Yogurt'] -> ['Eggs', 'Kidney Beans'] (Support: 2, Confidence: 0.67)\n",
      "    ['Onion'] -> ['Eggs', 'Kidney Beans'] (Support: 3, Confidence: 0.75)\n",
      "    ['Eggs'] -> ['Onion', 'Kidney Beans'] (Support: 3, Confidence: 0.75)\n",
      "    ['Kidney Beans'] -> ['Onion', 'Eggs'] (Support: 3, Confidence: 0.60)\n",
      "    ['Nutmeg'] -> ['Onion', 'Yogurt'] (Support: 2, Confidence: 1.00)\n",
      "    ['Yogurt'] -> ['Onion', 'Nutmeg'] (Support: 2, Confidence: 0.67)\n",
      "    ['Yogurt'] -> ['Onion', 'Kidney Beans'] (Support: 2, Confidence: 0.67)\n",
      "    ['Nutmeg'] -> ['Kidney Beans', 'Yogurt'] (Support: 2, Confidence: 1.00)\n",
      "    ['Yogurt'] -> ['Kidney Beans', 'Nutmeg'] (Support: 2, Confidence: 0.67)\n",
      "    ['Milk'] -> ['Kidney Beans', 'Yogurt'] (Support: 2, Confidence: 0.67)\n",
      "    ['Yogurt'] -> ['Milk', 'Kidney Beans'] (Support: 2, Confidence: 0.67)\n",
      "    ['Yogurt'] -> ['Onion', 'Eggs'] (Support: 2, Confidence: 0.67)\n",
      "    ['Milk'] -> ['Eggs', 'Kidney Beans'] (Support: 2, Confidence: 0.67)\n",
      "    ['Nutmeg'] -> ['Eggs', 'Kidney Beans'] (Support: 2, Confidence: 1.00)\n",
      "    ['Nutmeg'] -> ['Onion', 'Kidney Beans'] (Support: 2, Confidence: 1.00)\n",
      "    ['Yogurt'] -> ['Onion', 'Eggs', 'Kidney Beans'] (Support: 2, Confidence: 0.67)\n",
      "    ['Nutmeg'] -> ['Onion', 'Eggs', 'Yogurt'] (Support: 2, Confidence: 1.00)\n",
      "    ['Yogurt'] -> ['Onion', 'Eggs', 'Nutmeg'] (Support: 2, Confidence: 0.67)\n",
      "    ['Nutmeg'] -> ['Eggs', 'Kidney Beans', 'Yogurt'] (Support: 2, Confidence: 1.00)\n",
      "    ['Yogurt'] -> ['Eggs', 'Kidney Beans', 'Nutmeg'] (Support: 2, Confidence: 0.67)\n",
      "    ['Nutmeg'] -> ['Onion', 'Kidney Beans', 'Yogurt'] (Support: 2, Confidence: 1.00)\n",
      "    ['Yogurt'] -> ['Onion', 'Kidney Beans', 'Nutmeg'] (Support: 2, Confidence: 0.67)\n",
      "    ['Nutmeg'] -> ['Onion', 'Eggs', 'Kidney Beans'] (Support: 2, Confidence: 1.00)\n",
      "    ['Yogurt'] -> ['Onion', 'Nutmeg', 'Kidney Beans', 'Eggs'] (Support: 2, Confidence: 0.67)\n",
      "    ['Nutmeg'] -> ['Onion', 'Eggs', 'Kidney Beans', 'Yogurt'] (Support: 2, Confidence: 1.00)\n",
      "\n",
      "Cluster 1 (Number of transactions: 4):\n",
      "  ['Bread', 'Butter']\n",
      "  ['Bread', 'Milk']\n",
      "  ['Butter', 'Milk']\n",
      "  ['Bread', 'Butter', 'Milk']\n",
      "\n",
      "Applying Apriori to Cluster 1:\n",
      "  Frequent 1-itemsets:\n",
      "    ['Bread']: 3\n",
      "    ['Butter']: 3\n",
      "    ['Milk']: 3\n",
      "  Frequent 2-itemsets:\n",
      "    ['Butter', 'Bread']: 2\n",
      "    ['Milk', 'Bread']: 2\n",
      "    ['Butter', 'Milk']: 2\n",
      "  Association Rules:\n",
      "    ['Butter'] -> ['Bread'] (Support: 2, Confidence: 0.67)\n",
      "    ['Bread'] -> ['Butter'] (Support: 2, Confidence: 0.67)\n",
      "    ['Milk'] -> ['Bread'] (Support: 2, Confidence: 0.67)\n",
      "    ['Bread'] -> ['Milk'] (Support: 2, Confidence: 0.67)\n",
      "    ['Butter'] -> ['Milk'] (Support: 2, Confidence: 0.67)\n",
      "    ['Milk'] -> ['Butter'] (Support: 2, Confidence: 0.67)\n",
      "\n",
      "Cluster 3 (Number of transactions: 1):\n",
      "  ['Cheese', 'Wine']\n",
      "\n",
      "Applying Apriori to Cluster 3:\n",
      "  No association rules found for this cluster with the given confidence.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "def generate_frequent_itemsets(transactions, min_support):\n",
    "    item_counts = defaultdict(int)\n",
    "    for transaction in transactions:\n",
    "        for item in transaction:\n",
    "            item_counts[frozenset([item])] += 1\n",
    "    \n",
    "    L1 = {itemset: count for itemset, count in item_counts.items() if count >= min_support}\n",
    "    \n",
    "    frequent_itemsets = {1: L1}\n",
    "    k = 2\n",
    "    while True:\n",
    "        Ck = generate_candidate_itemsets(frequent_itemsets[k-1], k)\n",
    "        Lk = defaultdict(int)\n",
    "        for transaction in transactions:\n",
    "            for candidate in Ck:\n",
    "                if candidate.issubset(transaction):\n",
    "                    Lk[candidate] += 1\n",
    "        \n",
    "        Lk = {itemset: count for itemset, count in Lk.items() if not Lk[itemset] < min_support}\n",
    "        if not Lk:\n",
    "            break\n",
    "        frequent_itemsets[k] = Lk\n",
    "        k += 1\n",
    "    return frequent_itemsets\n",
    "\n",
    "def generate_candidate_itemsets(Lk_minus_1, k):\n",
    "    candidates = set()\n",
    "    items = sorted(list(Lk_minus_1.keys()))\n",
    "    for i in range(len(items)):\n",
    "        for j in range(i + 1, len(items)):\n",
    "            itemset1 = list(items[i])\n",
    "            itemset2 = list(items[j])\n",
    "            \n",
    "            itemset1.sort()\n",
    "            itemset2.sort()\n",
    "\n",
    "            if k == 2 or itemset1[:-1] == itemset2[:-1]:\n",
    "                new_candidate = frozenset(sorted(list(itemset1) + list(itemset2)))\n",
    "                candidates.add(new_candidate)\n",
    "    return candidates\n",
    "\n",
    "def generate_association_rules(frequent_itemsets, min_confidence):\n",
    "    rules = []\n",
    "    for k, Lk in frequent_itemsets.items():\n",
    "        if k > 1:\n",
    "            for itemset in Lk:\n",
    "                for antecedent_tuple in combinations(itemset, 1):\n",
    "                    antecedent = frozenset(antecedent_tuple)\n",
    "                    consequent = itemset - antecedent\n",
    "                    if consequent:\n",
    "                        confidence = Lk[itemset] / frequent_itemsets[len(antecedent)][antecedent]\n",
    "                        if confidence >= min_confidence:\n",
    "                            rules.append((antecedent, consequent, confidence, Lk[itemset]))\n",
    "    return rules\n",
    "\n",
    "def preprocess_transactions_for_clustering(transactions):\n",
    "    unique_items = sorted(list(set(item for sublist in transactions for item in sublist)))\n",
    "    item_to_idx = {item: idx for idx, item in enumerate(unique_items)}\n",
    "    \n",
    "    binary_vectors = []\n",
    "    for transaction in transactions:\n",
    "        vector = [0] * len(unique_items)\n",
    "        for item in transaction:\n",
    "            vector[item_to_idx[item]] = 1\n",
    "        binary_vectors.append(vector)\n",
    "    return np.array(binary_vectors), unique_items\n",
    "\n",
    "transactions_data = [\n",
    "    ['Milk', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "    ['Dill', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "    ['Milk', 'Apple', 'Kidney Beans', 'Eggs'],\n",
    "    ['Milk', 'Unicorn', 'Corn', 'Kidney Beans', 'Yogurt'],\n",
    "    ['Corn', 'Onion', 'Onion', 'Kidney Beans', 'Ice cream', 'Eggs'],\n",
    "    ['Bread', 'Butter'],\n",
    "    ['Bread', 'Milk'],\n",
    "    ['Butter', 'Milk'],\n",
    "    ['Bread', 'Butter', 'Milk'],\n",
    "    ['Cheese', 'Wine']\n",
    "]\n",
    "\n",
    "min_support = 2\n",
    "min_confidence = 0.6\n",
    "num_clusters = 3\n",
    "binary_data, all_items = preprocess_transactions_for_clustering(transactions_data)\n",
    "distances = pdist(binary_data, metric='jaccard')\n",
    "linked = linkage(distances, method='ward')\n",
    "clusters = fcluster(linked, num_clusters, criterion='maxclust')\n",
    "clustered_transactions = defaultdict(list)\n",
    "for i, cluster_id in enumerate(clusters):\n",
    "    clustered_transactions[cluster_id].append(transactions_data[i])\n",
    "print(\"Hierarchical Clustering Results:\")\n",
    "for cluster_id, cluster_transactions in clustered_transactions.items():\n",
    "    print(f\"\\nCluster {cluster_id} (Number of transactions: {len(cluster_transactions)}):\")\n",
    "    for trans in cluster_transactions:\n",
    "        print(f\"  {trans}\")\n",
    "    \n",
    "    print(f\"\\nApplying Apriori to Cluster {cluster_id}:\")\n",
    "    frequent_itemsets_cluster = generate_frequent_itemsets(cluster_transactions, min_support)\n",
    "    if frequent_itemsets_cluster:\n",
    "        for k, itemsets in frequent_itemsets_cluster.items():\n",
    "            if itemsets:\n",
    "                print(f\"  Frequent {k}-itemsets:\")\n",
    "                for itemset, count in itemsets.items():\n",
    "                    print(f\"    {list(itemset)}: {count}\")\n",
    "        \n",
    "        association_rules_cluster = generate_association_rules(frequent_itemsets_cluster, min_confidence)\n",
    "        if association_rules_cluster:\n",
    "            print(\"  Association Rules:\")\n",
    "            for antecedent, consequent, confidence, support in association_rules_cluster:\n",
    "                print(f\"    {list(antecedent)} -> {list(consequent)} (Support: {support}, Confidence: {confidence:.2f})\")\n",
    "        else:\n",
    "            print(\"  No association rules found for this cluster with the given confidence.\")\n",
    "    else:\n",
    "        print(\"  No frequent itemsets found for this cluster with the given support.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
