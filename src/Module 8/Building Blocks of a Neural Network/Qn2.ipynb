{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title: Understanding Hyperparameters\n",
    "\n",
    "# Task 1: Learning Rate\n",
    "# Set up a simple neural network for a classification task.\n",
    "# Experiment with a learning rate of 0.01, 0.001, and 0.0001.\n",
    "# Note the impact on the speed of convergence and training accuracy.\n",
    "\n",
    "# Task 2: Number of Neurons\n",
    "\n",
    "# Start with 64 neurons in a hidden layer.\n",
    "# Train the model, then try increasing to 128 and decreasing to 32 neurons.\n",
    "# Evaluate how the modelâ€™s performance changes with these configurations.\n",
    "\n",
    "\n",
    "# Task 3: Batch Size and Number of Epochs\n",
    "\n",
    "# Use batch sizes of 16, 64, and 256 in separate experiments.\n",
    "# Train the network for 10 epochs initially.\n",
    "# Observe how these settings affect the training time and model accuracy over multiple epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 04:51:34.346079: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748062294.368499   17114 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748062294.376167   17114 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748062294.396173   17114 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748062294.396209   17114 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748062294.396213   17114 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748062294.396216   17114 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-24 04:51:34.400471: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with learning rate = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2025-05-24 04:51:38.171052: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 04:51:38.492992: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 - 2s - 2ms/step - accuracy: 0.9315 - loss: 0.2272 - val_accuracy: 0.9596 - val_loss: 0.1355\n",
      "Epoch 2/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9574 - loss: 0.1408 - val_accuracy: 0.9537 - val_loss: 0.1636\n",
      "Epoch 3/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9656 - loss: 0.1155 - val_accuracy: 0.9594 - val_loss: 0.1533\n",
      "Epoch 4/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9694 - loss: 0.1026 - val_accuracy: 0.9624 - val_loss: 0.1593\n",
      "Epoch 5/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9717 - loss: 0.0969 - val_accuracy: 0.9651 - val_loss: 0.1428\n",
      "\n",
      "Training with learning rate = 0.001\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 04:51:47.379512: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 - 2s - 2ms/step - accuracy: 0.9020 - loss: 0.3566 - val_accuracy: 0.9439 - val_loss: 0.1973\n",
      "Epoch 2/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9501 - loss: 0.1717 - val_accuracy: 0.9592 - val_loss: 0.1414\n",
      "Epoch 3/5\n",
      "938/938 - 3s - 3ms/step - accuracy: 0.9636 - loss: 0.1264 - val_accuracy: 0.9630 - val_loss: 0.1238\n",
      "Epoch 4/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9705 - loss: 0.1017 - val_accuracy: 0.9684 - val_loss: 0.1089\n",
      "Epoch 5/5\n",
      "938/938 - 2s - 3ms/step - accuracy: 0.9754 - loss: 0.0836 - val_accuracy: 0.9705 - val_loss: 0.0975\n",
      "\n",
      "Training with learning rate = 0.0001\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 04:51:58.204482: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 - 2s - 2ms/step - accuracy: 0.7732 - loss: 0.9199 - val_accuracy: 0.8867 - val_loss: 0.4479\n",
      "Epoch 2/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.8959 - loss: 0.3915 - val_accuracy: 0.9071 - val_loss: 0.3335\n",
      "Epoch 3/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9116 - loss: 0.3187 - val_accuracy: 0.9184 - val_loss: 0.2887\n",
      "Epoch 4/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9206 - loss: 0.2830 - val_accuracy: 0.9262 - val_loss: 0.2639\n",
      "Epoch 5/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9273 - loss: 0.2592 - val_accuracy: 0.9286 - val_loss: 0.2457\n",
      "\n",
      "Training with 32 neurons in hidden layer\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 04:52:07.930946: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 - 2s - 2ms/step - accuracy: 0.8823 - loss: 0.4256 - val_accuracy: 0.9351 - val_loss: 0.2336\n",
      "Epoch 2/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9387 - loss: 0.2146 - val_accuracy: 0.9461 - val_loss: 0.1888\n",
      "Epoch 3/5\n",
      "938/938 - 1s - 1ms/step - accuracy: 0.9509 - loss: 0.1708 - val_accuracy: 0.9543 - val_loss: 0.1590\n",
      "Epoch 4/5\n",
      "938/938 - 1s - 2ms/step - accuracy: 0.9585 - loss: 0.1439 - val_accuracy: 0.9564 - val_loss: 0.1464\n",
      "Epoch 5/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9640 - loss: 0.1246 - val_accuracy: 0.9619 - val_loss: 0.1290\n",
      "\n",
      "Training with 64 neurons in hidden layer\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 04:52:16.343241: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 - 2s - 2ms/step - accuracy: 0.9006 - loss: 0.3551 - val_accuracy: 0.9396 - val_loss: 0.2074\n",
      "Epoch 2/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9495 - loss: 0.1791 - val_accuracy: 0.9554 - val_loss: 0.1546\n",
      "Epoch 3/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9620 - loss: 0.1326 - val_accuracy: 0.9642 - val_loss: 0.1198\n",
      "Epoch 4/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9693 - loss: 0.1060 - val_accuracy: 0.9664 - val_loss: 0.1100\n",
      "Epoch 5/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9738 - loss: 0.0875 - val_accuracy: 0.9671 - val_loss: 0.1033\n",
      "\n",
      "Training with 128 neurons in hidden layer\n",
      "Epoch 1/5\n",
      "938/938 - 3s - 3ms/step - accuracy: 0.9127 - loss: 0.3089 - val_accuracy: 0.9512 - val_loss: 0.1707\n",
      "Epoch 2/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9592 - loss: 0.1412 - val_accuracy: 0.9635 - val_loss: 0.1187\n",
      "Epoch 3/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9707 - loss: 0.0993 - val_accuracy: 0.9717 - val_loss: 0.0956\n",
      "Epoch 4/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9773 - loss: 0.0754 - val_accuracy: 0.9710 - val_loss: 0.0923\n",
      "Epoch 5/5\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9819 - loss: 0.0608 - val_accuracy: 0.9758 - val_loss: 0.0771\n",
      "\n",
      "Training with batch size = 16, epochs = 10\n",
      "Epoch 1/10\n",
      "3750/3750 - 6s - 1ms/step - accuracy: 0.9217 - loss: 0.2715 - val_accuracy: 0.9547 - val_loss: 0.1518\n",
      "Epoch 2/10\n",
      "3750/3750 - 5s - 1ms/step - accuracy: 0.9621 - loss: 0.1296 - val_accuracy: 0.9661 - val_loss: 0.1094\n",
      "Epoch 3/10\n",
      "3750/3750 - 5s - 1ms/step - accuracy: 0.9723 - loss: 0.0936 - val_accuracy: 0.9684 - val_loss: 0.1015\n",
      "Epoch 4/10\n",
      "3750/3750 - 5s - 1ms/step - accuracy: 0.9771 - loss: 0.0730 - val_accuracy: 0.9728 - val_loss: 0.0927\n",
      "Epoch 5/10\n",
      "3750/3750 - 10s - 3ms/step - accuracy: 0.9815 - loss: 0.0609 - val_accuracy: 0.9721 - val_loss: 0.0957\n",
      "Epoch 6/10\n",
      "3750/3750 - 5s - 1ms/step - accuracy: 0.9843 - loss: 0.0492 - val_accuracy: 0.9741 - val_loss: 0.0885\n",
      "Epoch 7/10\n",
      "3750/3750 - 5s - 1ms/step - accuracy: 0.9870 - loss: 0.0419 - val_accuracy: 0.9767 - val_loss: 0.0834\n",
      "Epoch 8/10\n",
      "3750/3750 - 5s - 1ms/step - accuracy: 0.9879 - loss: 0.0371 - val_accuracy: 0.9711 - val_loss: 0.1001\n",
      "Epoch 9/10\n",
      "3750/3750 - 5s - 1ms/step - accuracy: 0.9892 - loss: 0.0321 - val_accuracy: 0.9744 - val_loss: 0.0928\n",
      "Epoch 10/10\n",
      "3750/3750 - 5s - 1ms/step - accuracy: 0.9909 - loss: 0.0280 - val_accuracy: 0.9750 - val_loss: 0.0939\n",
      "\n",
      "Training with batch size = 64, epochs = 10\n",
      "Epoch 1/10\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9060 - loss: 0.3416 - val_accuracy: 0.9449 - val_loss: 0.1891\n",
      "Epoch 2/10\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9524 - loss: 0.1619 - val_accuracy: 0.9567 - val_loss: 0.1445\n",
      "Epoch 3/10\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9643 - loss: 0.1223 - val_accuracy: 0.9646 - val_loss: 0.1151\n",
      "Epoch 4/10\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9704 - loss: 0.1006 - val_accuracy: 0.9671 - val_loss: 0.1092\n",
      "Epoch 5/10\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9754 - loss: 0.0850 - val_accuracy: 0.9694 - val_loss: 0.0990\n",
      "Epoch 6/10\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9784 - loss: 0.0723 - val_accuracy: 0.9727 - val_loss: 0.0894\n",
      "Epoch 7/10\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9811 - loss: 0.0638 - val_accuracy: 0.9733 - val_loss: 0.0878\n",
      "Epoch 8/10\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9835 - loss: 0.0554 - val_accuracy: 0.9728 - val_loss: 0.0907\n",
      "Epoch 9/10\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9848 - loss: 0.0504 - val_accuracy: 0.9743 - val_loss: 0.0860\n",
      "Epoch 10/10\n",
      "938/938 - 2s - 2ms/step - accuracy: 0.9864 - loss: 0.0447 - val_accuracy: 0.9750 - val_loss: 0.0811\n",
      "\n",
      "Training with batch size = 256, epochs = 10\n",
      "Epoch 1/10\n",
      "235/235 - 1s - 6ms/step - accuracy: 0.8645 - loss: 0.5134 - val_accuracy: 0.9274 - val_loss: 0.2647\n",
      "Epoch 2/10\n",
      "235/235 - 1s - 3ms/step - accuracy: 0.9317 - loss: 0.2426 - val_accuracy: 0.9391 - val_loss: 0.2098\n",
      "Epoch 3/10\n",
      "235/235 - 1s - 3ms/step - accuracy: 0.9452 - loss: 0.1934 - val_accuracy: 0.9513 - val_loss: 0.1751\n",
      "Epoch 4/10\n",
      "235/235 - 1s - 3ms/step - accuracy: 0.9539 - loss: 0.1613 - val_accuracy: 0.9578 - val_loss: 0.1543\n",
      "Epoch 5/10\n",
      "235/235 - 1s - 3ms/step - accuracy: 0.9599 - loss: 0.1400 - val_accuracy: 0.9617 - val_loss: 0.1370\n",
      "Epoch 6/10\n",
      "235/235 - 1s - 3ms/step - accuracy: 0.9649 - loss: 0.1227 - val_accuracy: 0.9629 - val_loss: 0.1291\n",
      "Epoch 7/10\n",
      "235/235 - 1s - 3ms/step - accuracy: 0.9679 - loss: 0.1103 - val_accuracy: 0.9647 - val_loss: 0.1205\n",
      "Epoch 8/10\n",
      "235/235 - 1s - 3ms/step - accuracy: 0.9719 - loss: 0.0996 - val_accuracy: 0.9657 - val_loss: 0.1161\n",
      "Epoch 9/10\n",
      "235/235 - 1s - 3ms/step - accuracy: 0.9745 - loss: 0.0905 - val_accuracy: 0.9689 - val_loss: 0.1095\n",
      "Epoch 10/10\n",
      "235/235 - 1s - 3ms/step - accuracy: 0.9765 - loss: 0.0824 - val_accuracy: 0.9680 - val_loss: 0.1123\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "def build_model(num_neurons=64, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        Flatten(input_shape=(28, 28)),\n",
    "        Dense(num_neurons, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Task 1: Learning Rate experiments\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nTraining with learning rate = {lr}\")\n",
    "    model = build_model(learning_rate=lr)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                        epochs=5, batch_size=64, verbose=2)\n",
    "\n",
    "# Task 2: Number of Neurons experiments\n",
    "neurons_list = [32, 64, 128]\n",
    "for neurons in neurons_list:\n",
    "    print(f\"\\nTraining with {neurons} neurons in hidden layer\")\n",
    "    model = build_model(num_neurons=neurons, learning_rate=0.001)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                        epochs=5, batch_size=64, verbose=2)\n",
    "\n",
    "# Task 3: Batch Size and Epochs experiments\n",
    "batch_sizes = [16, 64, 256]\n",
    "epochs = 10\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"\\nTraining with batch size = {batch_size}, epochs = {epochs}\")\n",
    "    model = build_model(num_neurons=64, learning_rate=0.001)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "                        epochs=epochs, batch_size=batch_size, verbose=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
