{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title: Neural Networks\n",
    "\n",
    "# 1. Task 1: Digit Recognition with a Simple Neural Network\n",
    "# Task: Understand how a neural network identifies handwritten digits.\n",
    "# Exercise: Input an image of a handwritten digit into a pre-trained simple feedforward neural network and observe the output prediction.\n",
    "\n",
    "# 2. Task 2: Predicting House Prices\n",
    "# Task: Use a neural network to predict house prices based on features like location, size, and number of rooms.\n",
    "# Exercise: Experiment with different input data to observe how the network's predictions change.\n",
    "\n",
    "# 3. Task 3: Language Translation\n",
    "# Task: A neural network powers language translation tools to convert text from one language to another.\n",
    "# Exercise: Provide a sentence in English and get the translated version in another language using a pre-trained translation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 10:54:57.691880: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-28 10:54:57.695461: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-28 10:54:57.704331: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748429697.724535   18232 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748429697.728897   18232 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748429697.746753   18232 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748429697.746767   18232 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748429697.746769   18232 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748429697.746771   18232 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-28 10:54:57.750560: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/vscode/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-05-28 10:55:02.640008: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the digit recognition model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 10:55:02.916741: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\n",
      "Original image (flattened):\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "True Digit: 1\n",
      "Predicted Digit: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
    "x_test = x_test.reshape(-1, 28 * 28).astype(\"float32\") / 255.0\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', input_shape=(784,)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Training the digit recognition model...\")\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32, verbose=0)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "random_index = np.random.randint(0, len(x_test))\n",
    "sample_image = x_test[random_index]\n",
    "true_label = y_test[random_index]\n",
    "\n",
    "prediction = model.predict(sample_image.reshape(1, -1))\n",
    "predicted_digit = np.argmax(prediction)\n",
    "\n",
    "print(f\"\\nOriginal image (flattened):\\n{sample_image[:10]}...\")\n",
    "print(f\"True Digit: {true_label}\")\n",
    "print(f\"Predicted Digit: {predicted_digit}\")\n",
    "\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.imshow(sample_image.reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"Predicted: {predicted_digit}, True: {true_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the house price prediction model...\n",
      "Model training complete.\n",
      "\n",
      "Experimenting with house price predictions:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Predicted price for a 1500 sqft, 3 bed, 2 bath, loc 7.5, 2000 built house: $149,758.50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Predicted price for a 2500 sqft, 4 bed, 3 bath, loc 9.0, 2010 built house: $233,304.78\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Predicted price for a 1000 sqft, 2 bed, 1 bath, loc 3.0, 1970 built house: $89,722.47\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "num_samples = 1000\n",
    "data = {\n",
    "    'Size_sqft': np.random.randint(800, 3000, num_samples),\n",
    "    'Num_Bedrooms': np.random.randint(2, 6, num_samples),\n",
    "    'Num_Bathrooms': np.random.randint(1, 4, num_samples),\n",
    "    'Location_Score': np.random.uniform(1, 10, num_samples),\n",
    "    'Year_Built': np.random.randint(1950, 2020, num_samples)\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['Price'] = (df['Size_sqft'] * 50) + \\\n",
    "              (df['Num_Bedrooms'] * 10000) + \\\n",
    "              (df['Num_Bathrooms'] * 7000) + \\\n",
    "              (df['Location_Score'] * 5000) + \\\n",
    "              ((2025 - df['Year_Built']) * -100) + \\\n",
    "              np.random.normal(0, 15000, num_samples)\n",
    "df['Price'] = np.maximum(50000, df['Price'])\n",
    "df.to_csv('house_data.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('house_data.csv')\n",
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "print(\"\\nTraining the house price prediction model...\")\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0, validation_split=0.1)\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "def predict_house_price(model, scaler_X, scaler_y, size, bedrooms, bathrooms, location_score, year_built):\n",
    "    input_data = np.array([[size, bedrooms, bathrooms, location_score, year_built]])\n",
    "    input_scaled = scaler_X.transform(input_data)\n",
    "    predicted_scaled = model.predict(input_scaled)[0][0]\n",
    "    predicted_price = scaler_y.inverse_transform([[predicted_scaled]])[0][0]\n",
    "    return predicted_price\n",
    "\n",
    "print(\"\\nExperimenting with house price predictions:\")\n",
    "price1 = predict_house_price(model, scaler_X, scaler_y, 1500, 3, 2, 7.5, 2000)\n",
    "print(f\"Predicted price for a 1500 sqft, 3 bed, 2 bath, loc 7.5, 2000 built house: ${price1:,.2f}\")\n",
    "\n",
    "price2 = predict_house_price(model, scaler_X, scaler_y, 2500, 4, 3, 9.0, 2010)\n",
    "print(f\"Predicted price for a 2500 sqft, 4 bed, 3 bath, loc 9.0, 2010 built house: ${price2:,.2f}\")\n",
    "\n",
    "price3 = predict_house_price(model, scaler_X, scaler_y, 1000, 2, 1, 3.0, 1970)\n",
    "print(f\"Predicted price for a 1000 sqft, 2 bed, 1 bath, loc 3.0, 1970 built house: ${price3:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Language Translation (Conceptual Demonstration) ---\n",
      "English: 'Hello world' -> Spanish (simple): 'hola mundo'\n",
      "English: 'How are you' -> Spanish (simple): 'cómo estás'\n",
      "English: 'Thank you goodbye' -> Spanish (simple): 'thank you adiós'\n",
      "\n",
      "--- How a Real Neural Network (like a Transformer) Works for Translation ---\n",
      "1. Tokenization: Breaks down the input sentence into smaller units (words or sub-words).\n",
      "   Example: 'Hello world' -> ['Hello', 'world']\n",
      "2. Embedding: Converts tokens into numerical vectors that capture their semantic meaning.\n",
      "3. Encoder: Processes the input sequence, understanding context and relationships between words.\n",
      "   (Often uses attention mechanisms to weigh importance of different words.)\n",
      "4. Decoder: Generates the output sequence in the target language, attending to the encoded input and previously generated words.\n",
      "5. Output Layer: Maps the decoder's output to probabilities for each word in the target language's vocabulary, selecting the most probable word.\n",
      "This process iterates until an 'end of sentence' token is generated.\n",
      "\n",
      "To truly implement this, you would use libraries like Hugging Face Transformers to load pre-trained models such as 'Helsinki-NLP/opus-mt-en-es' for English to Spanish.\n"
     ]
    }
   ],
   "source": [
    "def simple_translate(sentence, target_language='Spanish'):\n",
    "    if target_language == 'Spanish':\n",
    "        translations = {\n",
    "            \"hello\": \"hola\",\n",
    "            \"world\": \"mundo\",\n",
    "            \"how are you\": \"cómo estás\",\n",
    "            \"i am fine\": \"estoy bien\",\n",
    "            \"thank you\": \"gracias\",\n",
    "            \"goodbye\": \"adiós\",\n",
    "            \"what is your name\": \"cómo te llamas\"\n",
    "        }\n",
    "        words = sentence.lower().split()\n",
    "        translated_words = []\n",
    "        for word in words:\n",
    "            found = False\n",
    "            for phrase, trans in translations.items():\n",
    "                if word in phrase.split():\n",
    "                    translated_words.append(trans if phrase == word else word)\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                translated_words.append(word)\n",
    "        \n",
    "        # Simple phrase matching, not perfect for complex sentences\n",
    "        if \"how are you\" in sentence.lower():\n",
    "            return \"cómo estás\"\n",
    "        elif \"what is your name\" in sentence.lower():\n",
    "            return \"cómo te llamas\"\n",
    "        \n",
    "        return ' '.join(translated_words)\n",
    "    else:\n",
    "        return \"Translation for this language is not available in this simple model.\"\n",
    "\n",
    "print(\"\\n--- Language Translation (Conceptual Demonstration) ---\")\n",
    "english_sentence1 = \"Hello world\"\n",
    "translated_sentence1 = simple_translate(english_sentence1, 'Spanish')\n",
    "print(f\"English: '{english_sentence1}' -> Spanish (simple): '{translated_sentence1}'\")\n",
    "\n",
    "english_sentence2 = \"How are you\"\n",
    "translated_sentence2 = simple_translate(english_sentence2, 'Spanish')\n",
    "print(f\"English: '{english_sentence2}' -> Spanish (simple): '{translated_sentence2}'\")\n",
    "\n",
    "english_sentence3 = \"Thank you goodbye\"\n",
    "translated_sentence3 = simple_translate(english_sentence3, 'Spanish')\n",
    "print(f\"English: '{english_sentence3}' -> Spanish (simple): '{translated_sentence3}'\")\n",
    "\n",
    "print(\"\\n--- How a Real Neural Network (like a Transformer) Works for Translation ---\")\n",
    "print(\"1. Tokenization: Breaks down the input sentence into smaller units (words or sub-words).\")\n",
    "print(\"   Example: 'Hello world' -> ['Hello', 'world']\")\n",
    "print(\"2. Embedding: Converts tokens into numerical vectors that capture their semantic meaning.\")\n",
    "print(\"3. Encoder: Processes the input sequence, understanding context and relationships between words.\")\n",
    "print(\"   (Often uses attention mechanisms to weigh importance of different words.)\")\n",
    "print(\"4. Decoder: Generates the output sequence in the target language, attending to the encoded input and previously generated words.\")\n",
    "print(\"5. Output Layer: Maps the decoder's output to probabilities for each word in the target language's vocabulary, selecting the most probable word.\")\n",
    "print(\"This process iterates until an 'end of sentence' token is generated.\")\n",
    "print(\"\\nTo truly implement this, you would use libraries like Hugging Face Transformers to load pre-trained models such as 'Helsinki-NLP/opus-mt-en-es' for English to Spanish.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
