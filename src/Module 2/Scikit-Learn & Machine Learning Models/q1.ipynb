{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Introduction to Scikit-Learn & Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Installing and Setting Up Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n",
    "# Task 1: Installing and Setting Up Scikit-Learn\n",
    "\n",
    "# Step 1: Check if Python is installed\n",
    "import sys\n",
    "print(f\"Your Python version: {sys.version}\")\n",
    "\n",
    "# Step 2: Install scikit-learn using pip (if not already installed)\n",
    "# You'll typically run this command in your terminal or command prompt:\n",
    "# pip install -U scikit-learn\n",
    "\n",
    "# Note: It's best practice to do this within a virtual environment.\n",
    "# If you don't have pip installed, you might need to install it first:\n",
    "# https://pip.pypa.io/en/stable/installation/\n",
    "\n",
    "# Step 3: Verify the installation\n",
    "try:\n",
    "    import sklearn\n",
    "    print(f\"Scikit-learn version: {sklearn.__version__}\")\n",
    "    print(\"Scikit-learn is successfully installed and set up!\")\n",
    "except ImportError:\n",
    "    print(\"Scikit-learn is not installed. Please run 'pip install -U scikit-learn' in your terminal.\")\n",
    "\n",
    "# Optional: Install other useful libraries\n",
    "# pip install numpy scipy pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Task 2: Loading in-built Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n",
    "# Task 2: Loading In-built Datasets in Scikit-Learn\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "# Step 1: Load the Iris dataset\n",
    "iris = datasets.load_iris()\n",
    "print(\"Iris dataset loaded.\")\n",
    "print(f\"Type of iris object: {type(iris)}\")\n",
    "print(f\"Keys in iris object: {iris.keys()}\")\n",
    "print(\"\\nIris feature names:\", iris.feature_names)\n",
    "print(\"Shape of Iris data:\", iris.data.shape)\n",
    "print(\"Shape of Iris target:\", iris.target.shape)\n",
    "print(\"\\nFirst 5 samples of Iris data:\\n\", iris.data[:5])\n",
    "print(\"\\nTarget values for the first 5 samples:\", iris.target[:5])\n",
    "print(\"\\nTarget names:\", iris.target_names)\n",
    "\n",
    "# Step 2: Load the Digits dataset\n",
    "digits = datasets.load_digits()\n",
    "print(\"\\nDigits dataset loaded.\")\n",
    "print(f\"Type of digits object: {type(digits)}\")\n",
    "print(f\"Keys in digits object: {digits.keys()}\")\n",
    "print(\"\\nDigits feature names (pixel intensities):\", digits.feature_names[:10], \"...\") # Showing first 10\n",
    "print(\"Shape of Digits data:\", digits.data.shape)\n",
    "print(\"Shape of Digits target:\", digits.target.shape)\n",
    "print(\"\\nFirst sample of Digits data (as a flattened array):\\n\", digits.data[0])\n",
    "print(\"\\nTarget value for the first sample:\", digits.target[0])\n",
    "print(\"\\nTarget names (digit classes):\", digits.target_names)\n",
    "\n",
    "# Step 3: Load the Breast Cancer dataset\n",
    "breast_cancer = datasets.load_breast_cancer()\n",
    "print(\"\\nBreast Cancer dataset loaded.\")\n",
    "print(f\"Type of breast_cancer object: {type(breast_cancer)}\")\n",
    "print(f\"Keys in breast_cancer object: {breast_cancer.keys()}\")\n",
    "print(\"\\nBreast Cancer feature names:\", breast_cancer.feature_names)\n",
    "print(\"Shape of Breast Cancer data:\", breast_cancer.data.shape)\n",
    "print(\"Shape of Breast Cancer target:\", breast_cancer.target.shape)\n",
    "print(\"\\nFirst 5 samples of Breast Cancer data:\\n\", breast_cancer.data[:5])\n",
    "print(\"\\nTarget values for the first 5 samples:\", breast_cancer.target[:5])\n",
    "print(\"\\nTarget names:\", breast_cancer.target_names)\n",
    "\n",
    "# Information about a dataset can be accessed using its DESCR attribute\n",
    "print(\"\\nDescription of the Iris dataset:\\n\", iris.DESCR[:500], \"...\") # Showing first 500 characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Understanding Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n",
    "arr = [1, 2, 3, 4, 5]\n",
    "print(arr[0])  # Accessing the first element\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Building a Simple ML Model in Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Simple Linear Regression\n",
    "Implement linear regression with a small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n",
    "# Task 1: Simple Linear Regression with a Small Dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Create a small synthetic dataset\n",
    "np.random.seed(42)  # for reproducibility\n",
    "X = np.array([1, 2, 3, 4, 5, 6]).reshape(-1, 1)  # Independent variable (feature)\n",
    "y = np.array([2, 3.5, 5, 5.5, 7, 8]) + np.random.normal(0, 0.5, 6) # Dependent variable (target) with some noise\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n",
    "# Step 3: Create and train a Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nMean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R2) Score: {r2:.2f}\")\n",
    "\n",
    "# Step 6: Visualize the results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_train, y_train, color='blue', label='Training Data')\n",
    "plt.scatter(X_test, y_test, color='green', label='Testing Data')\n",
    "plt.plot(X_test, y_pred, color='red', linewidth=2, label='Linear Regression Line')\n",
    "plt.xlabel('X (Independent Variable)')\n",
    "plt.ylabel('y (Dependent Variable)')\n",
    "plt.title('Simple Linear Regression')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Step 7: Print the model coefficients\n",
    "print(f\"\\nIntercept (b0): {model.intercept_:.2f}\")\n",
    "print(f\"Coefficient (b1): {model.coef_[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Decision Tree Classifier\n",
    "Build a decision tree model with the Iris dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n",
    "# Task 2: Decision Tree Classifier with the Iris Dataset\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Step 1: Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "class_names = iris.target_names\n",
    "\n",
    "print(\"Iris dataset loaded.\")\n",
    "print(\"Feature names:\", feature_names)\n",
    "print(\"Class names:\", class_names)\n",
    "print(\"Shape of data:\", X.shape)\n",
    "print(\"Shape of target:\", y.shape)\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(\"\\nData split into training and testing sets.\")\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n",
    "# Step 3: Create and train a Decision Tree Classifier model\n",
    "# You can adjust hyperparameters like max_depth, min_samples_split, etc.\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nDecision Tree Classifier model trained.\")\n",
    "\n",
    "# Step 4: Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\nPredictions on the test set:\", y_pred)\n",
    "print(\"Actual values on the test set:\", y_test)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy of the Decision Tree Classifier: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Step 6: Visualize the Decision Tree (Optional, requires graphviz)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(model, feature_names=feature_names, class_names=class_names, filled=True)\n",
    "plt.title(\"Decision Tree Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: K-Nearest Neighbors Classifier\n",
    "Use the KNN algorithm on the digits dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Training a Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Logistic Regression\n",
    "Train a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Support Vector Machine\n",
    "Train a Support Vector Classifier on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Naive Bayes Classifier\n",
    "Train a Gaussian Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Understanding Model Performance & Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Using Confusion Matrix\n",
    "Evaluate a model with a confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Cross-validation Score\n",
    "Perform cross-validation with k-fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Hyperparameter Tuning using Grid Search\n",
    "Optimize hyperparameters using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
